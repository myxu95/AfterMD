#!/usr/bin/env python3
"""
MDè½¨è¿¹åˆ†æè¿è¡Œè„šæœ¬

åŸºäºè´¨é‡æ£€æµ‹å’ŒPBCé¢„å¤„ç†åçš„è§„èŒƒæ–‡ä»¶è¿›è¡ŒRMSDç­‰åç»­åˆ†æã€‚

ä½¿ç”¨æ–¹æ³•:
    python run_trajectory_analysis.py /path/to/processed/simulations
    python run_trajectory_analysis.py /path/to/processed/simulations --analysis rmsd rg distances
    python run_trajectory_analysis.py /path/to/processed/simulations --single /path/to/specific/md
"""

import sys
import argparse
import logging
import time
from pathlib import Path
from typing import List, Dict, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from aftermd.analysis.analysis_pipeline import AnalysisPipeline, create_analysis_pipeline


def setup_logging(log_level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('trajectory_analysis.log')
        ]
    )


def find_processed_trajectories(root_dir: Path) -> List[Dict[str, str]]:
    """
    å‘ç°å·²å¤„ç†çš„è½¨è¿¹æ–‡ä»¶
    
    æŸ¥æ‰¾ç¬¦åˆä»¥ä¸‹ç»“æ„çš„ç›®å½•:
    {MD_Product}_processed/
    â”œâ”€â”€ {MD_Product}_processed.xtc
    â””â”€â”€ md.gro (æˆ–å…¶ä»–å‚è€ƒç»“æ„)
    
    Args:
        root_dir: æ ¹ç›®å½•è·¯å¾„
        
    Returns:
        è½¨è¿¹æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
    """
    trajectories = []
    
    # æŸ¥æ‰¾æ‰€æœ‰ *_processed ç›®å½•
    for processed_dir in root_dir.rglob("*_processed"):
        if not processed_dir.is_dir():
            continue
        
        # æŸ¥æ‰¾è½¨è¿¹æ–‡ä»¶
        trajectory_files = list(processed_dir.glob("*.xtc")) + list(processed_dir.glob("*.trr"))
        if not trajectory_files:
            continue
        
        # é€‰æ‹©æœ€å¤§çš„è½¨è¿¹æ–‡ä»¶ (é€šå¸¸æ˜¯ä¸»è¦çš„å¤„ç†ç»“æœ)
        trajectory_file = max(trajectory_files, key=lambda f: f.stat().st_size)
        
        # æŸ¥æ‰¾å‚è€ƒç»“æ„æ–‡ä»¶
        reference_files = (
            list(processed_dir.glob("md.gro")) +
            list(processed_dir.glob("*.gro")) +
            list(processed_dir.glob("*.tpr")) +
            list(processed_dir.glob("*.pdb"))
        )
        
        if not reference_files:
            print(f"âš ï¸  è·³è¿‡ {processed_dir.name}: æœªæ‰¾åˆ°å‚è€ƒç»“æ„æ–‡ä»¶")
            continue
        
        # ä¼˜å…ˆé€‰æ‹© md.gro
        reference_file = None
        for ref in reference_files:
            if ref.name == "md.gro":
                reference_file = ref
                break
        if not reference_file:
            reference_file = reference_files[0]
        
        trajectories.append({
            "name": processed_dir.name,
            "trajectory": str(trajectory_file),
            "reference": str(reference_file),
            "output_dir": str(processed_dir / "analysis")
        })
    
    return trajectories


def analyze_single_trajectory(trajectory_info: Dict[str, str], 
                            analysis_types: List[str],
                            **kwargs) -> Dict[str, str]:
    """
    åˆ†æå•ä¸ªè½¨è¿¹
    
    Args:
        trajectory_info: è½¨è¿¹ä¿¡æ¯å­—å…¸
        analysis_types: è¦è¿è¡Œçš„åˆ†æç±»å‹åˆ—è¡¨
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        åˆ†æç»“æœæ‘˜è¦
    """
    name = trajectory_info["name"]
    
    try:
        # åˆ›å»ºåˆ†ææµæ°´çº¿
        pipeline = create_analysis_pipeline(
            processed_trajectory=trajectory_info["trajectory"],
            reference_structure=trajectory_info["reference"],
            output_dir=trajectory_info["output_dir"]
        )
        
        # ç¡®å®šè¦è¿è¡Œçš„åˆ†æ
        enable_rmsd = "rmsd" in analysis_types
        enable_rg = "rg" in analysis_types or "radius_gyration" in analysis_types
        enable_distances = "distances" in analysis_types or "distance" in analysis_types
        enable_rdf = "rdf" in analysis_types
        enable_hbonds = "hbonds" in analysis_types or "hydrogen_bonds" in analysis_types
        
        # è¿è¡Œç»¼åˆåˆ†æ
        results = pipeline.run_comprehensive_analysis(
            enable_rmsd=enable_rmsd,
            enable_rg=enable_rg,
            enable_distances=enable_distances,
            enable_rdf=enable_rdf,
            enable_hbonds=enable_hbonds,
            **kwargs
        )
        
        # ä¿å­˜ç»“æœ
        pipeline.save_results()
        
        summary = results.get("analysis_summary", {})
        completed = len(summary.get("completed_analyses", []))
        total_time = summary.get("total_time_seconds", 0)
        
        return {
            "status": "success",
            "name": name,
            "completed_analyses": completed,
            "total_time": total_time,
            "output_dir": trajectory_info["output_dir"]
        }
        
    except Exception as e:
        return {
            "status": "failed",
            "name": name,
            "error": str(e)
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="MDè½¨è¿¹åˆ†æå·¥å…· - åŸºäºé¢„å¤„ç†è½¨è¿¹è¿›è¡ŒRMSDç­‰åˆ†æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  åˆ†ææ‰€æœ‰é¢„å¤„ç†è½¨è¿¹:
    python run_trajectory_analysis.py /path/to/processed/simulations
    
  åªè¿›è¡ŒRMSDå’Œå›è½¬åŠå¾„åˆ†æ:
    python run_trajectory_analysis.py /path/to/processed/simulations --analysis rmsd rg
    
  åˆ†æå•ä¸ªè½¨è¿¹:
    python run_trajectory_analysis.py /path/to/processed/simulations --single md_product_1_processed
    
  å¹¶è¡Œåˆ†æ (4ä¸ªè¿›ç¨‹):
    python run_trajectory_analysis.py /path/to/processed/simulations --max-workers 4
    
  è¯¦ç»†æ—¥å¿—:
    python run_trajectory_analysis.py /path/to/processed/simulations --log-level DEBUG
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        "processed_root",
        help="åŒ…å«å·²å¤„ç†è½¨è¿¹çš„æ ¹ç›®å½•"
    )
    
    # åˆ†æé€‰é¡¹
    parser.add_argument(
        "--analysis", "-a",
        nargs="+",
        choices=["rmsd", "rg", "radius_gyration", "distances", "distance", "rdf", "hbonds", "hydrogen_bonds"],
        default=["rmsd", "rg", "distances"],
        help="è¦è¿è¡Œçš„åˆ†æç±»å‹ (é»˜è®¤: rmsd rg distances)"
    )
    
    parser.add_argument(
        "--single", "-s",
        help="åªåˆ†ææŒ‡å®šçš„å•ä¸ªè½¨è¿¹ç›®å½•å"
    )
    
    # å¹¶è¡Œå¤„ç†
    parser.add_argument(
        "--max-workers",
        type=int,
        default=1,
        help="æœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•° (é»˜è®¤: 1)"
    )
    
    # æ—¥å¿—é€‰é¡¹
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯"
    )
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="å¹²è¿è¡Œæ¨¡å¼ï¼Œåªæ˜¾ç¤ºå°†è¦åˆ†æçš„è½¨è¿¹"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    log_level = "DEBUG" if args.verbose else args.log_level
    setup_logging(log_level)
    logger = logging.getLogger(__name__)
    
    # éªŒè¯è¾“å…¥ç›®å½•
    processed_root = Path(args.processed_root)
    if not processed_root.exists():
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ - {processed_root}")
        return 1
    
    if not processed_root.is_dir():
        print(f"âŒ é”™è¯¯: è·¯å¾„ä¸æ˜¯ç›®å½• - {processed_root}")
        return 1
    
    # å‘ç°è½¨è¿¹æ–‡ä»¶
    print("ğŸ” æœç´¢å·²å¤„ç†çš„è½¨è¿¹æ–‡ä»¶...")
    trajectories = find_processed_trajectories(processed_root)
    
    if not trajectories:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å·²å¤„ç†çš„è½¨è¿¹æ–‡ä»¶")
        print("ğŸ’¡ ç¡®ä¿ç›®å½•ç»“æ„ä¸º: {MD_Product}_processed/{MD_Product}_processed.xtc")
        return 1
    
    print(f"ğŸ“ å‘ç° {len(trajectories)} ä¸ªå·²å¤„ç†çš„è½¨è¿¹")
    
    # è¿‡æ»¤å•ä¸ªè½¨è¿¹
    if args.single:
        trajectories = [t for t in trajectories if args.single in t["name"]]
        if not trajectories:
            print(f"âŒ æœªæ‰¾åˆ°æŒ‡å®šçš„è½¨è¿¹: {args.single}")
            return 1
        print(f"ğŸ¯ ä»…åˆ†ææŒ‡å®šè½¨è¿¹: {trajectories[0]['name']}")
    
    # å¹²è¿è¡Œæ¨¡å¼
    if args.dry_run:
        print("\nğŸ” å¹²è¿è¡Œæ¨¡å¼ - å°†è¦åˆ†æçš„è½¨è¿¹:")
        for i, traj in enumerate(trajectories, 1):
            print(f"  {i:2d}. {traj['name']}")
            print(f"      è½¨è¿¹: {Path(traj['trajectory']).name}")
            print(f"      å‚è€ƒ: {Path(traj['reference']).name}")
            print(f"      è¾“å‡º: {traj['output_dir']}")
        print(f"\nğŸ“Š åˆ†æç±»å‹: {', '.join(args.analysis)}")
        print(f"ğŸ”§ å¹¶è¡Œè¿›ç¨‹: {args.max_workers}")
        return 0
    
    # æ˜¾ç¤ºåˆ†æè®¡åˆ’
    print(f"\nğŸš€ å¼€å§‹è½¨è¿¹åˆ†æ")
    print(f"ğŸ“Š åˆ†æç±»å‹: {', '.join(args.analysis)}")
    print(f"ğŸ”§ å¹¶è¡Œè¿›ç¨‹: {args.max_workers}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: å„è½¨è¿¹çš„ analysis/ å­ç›®å½•")
    print("=" * 60)
    
    # å¼€å§‹åˆ†æ
    start_time = time.time()
    results = []
    
    if args.max_workers == 1:
        # ä¸²è¡Œå¤„ç†
        for i, traj_info in enumerate(trajectories, 1):
            print(f"\n[{i:3d}/{len(trajectories)}] åˆ†æ {traj_info['name']}")
            result = analyze_single_trajectory(traj_info, args.analysis)
            results.append(result)
            
            if result["status"] == "success":
                print(f"   âœ… æˆåŠŸ (è€—æ—¶: {result['total_time']:.1f}s, åˆ†æ: {result['completed_analyses']})")
            else:
                print(f"   âŒ å¤±è´¥: {result['error']}")
    
    else:
        # å¹¶è¡Œå¤„ç†
        print(f"\nğŸ”„ ä½¿ç”¨ {args.max_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œåˆ†æ...")
        
        with ProcessPoolExecutor(max_workers=args.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_traj = {
                executor.submit(analyze_single_trajectory, traj_info, args.analysis): traj_info
                for traj_info in trajectories
            }
            
            # æ”¶é›†ç»“æœ
            for i, future in enumerate(as_completed(future_to_traj), 1):
                traj_info = future_to_traj[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    if result["status"] == "success":
                        print(f"[{i:3d}/{len(trajectories)}] âœ… {result['name']} (è€—æ—¶: {result['total_time']:.1f}s)")
                    else:
                        print(f"[{i:3d}/{len(trajectories)}] âŒ {result['name']}: {result['error']}")
                        
                except Exception as e:
                    print(f"[{i:3d}/{len(trajectories)}] âŒ {traj_info['name']}: è¿›ç¨‹å¼‚å¸¸ - {e}")
                    results.append({
                        "status": "failed",
                        "name": traj_info["name"],
                        "error": f"è¿›ç¨‹å¼‚å¸¸: {e}"
                    })
    
    # ç»Ÿè®¡ç»“æœ
    end_time = time.time()
    total_time = end_time - start_time
    
    successful = [r for r in results if r["status"] == "success"]
    failed = [r for r in results if r["status"] == "failed"]
    
    print(f"\n{'='*60}")
    print("ğŸ“Š è½¨è¿¹åˆ†æå®Œæˆ!")
    print(f"{'='*60}")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
    print(f"âœ… æˆåŠŸ: {len(successful)} ä¸ªè½¨è¿¹")
    print(f"âŒ å¤±è´¥: {len(failed)} ä¸ªè½¨è¿¹")
    
    if successful:
        total_analysis_time = sum(r["total_time"] for r in successful)
        avg_time = total_analysis_time / len(successful)
        print(f"ğŸ“ˆ å¹³å‡åˆ†ææ—¶é—´: {avg_time:.1f} ç§’/è½¨è¿¹")
        
        print(f"\nğŸ“ åˆ†æç»“æœä½ç½®:")
        for result in successful[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"   â€¢ {result['name']}: {result['output_dir']}")
        if len(successful) > 5:
            print(f"   ... ä»¥åŠå…¶ä»– {len(successful) - 5} ä¸ª")
    
    if failed:
        print(f"\nâŒ å¤±è´¥çš„è½¨è¿¹:")
        for result in failed:
            print(f"   â€¢ {result['name']}: {result['error']}")
    
    print(f"\nğŸ’¡ æŸ¥çœ‹å„è½¨è¿¹çš„åˆ†ææŠ¥å‘Š: */analysis/reports/analysis_report.md")
    print(f"ğŸ’¡ æŸ¥çœ‹ç»˜å›¾ç»“æœ: */analysis/plots/")
    
    return 0 if not failed else 1


if __name__ == "__main__":
    exit(main())